name: Build GCP Artifact Registry Image

on:
  workflow_dispatch:
    inputs:
      cpu:
        description: CPU for the agent
        required: true
        default: '512'
        type: choice
        options: ['256', '512', '1024', '2048', '4096']
      memory:
        description: Memory for the agent
        required: true
        default: '1024'
        type: choice
        options: ['512', '1024', '2048', '4096', '5120', '6144', '7168', '8192']
      gcs_path:
        description: GCS path in the format bucket/path
        required: true
        default: 'prefect-orion/flows'
      block_name:
        description: Name of the GCS and Cloud Run blocks
        required: true
        default: 'default'
      prefect-version:
        description: Prefect version for flows
        required: true
        default: '2.*'
        type: string
      region:
        description: GCP Region
        required: true
        default: 'us-east1'
        type: string
      ar_repository:
        description: Artifact Registry Repository
        required: true
        default: 'sls' # 'us-east1-docker.pkg.dev/prefect-community/sls/prefect:latest'
        type: string

env:
  PROJECT_ID: prefect-community
  AR_REPOSITORY: ${{ github.event.inputs.ar_repository }}
  REGION: ${{ github.event.inputs.region }}
  GCS_PATH: ${{ github.event.inputs.gcs_path }}
  SERVICE: prefect

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Login to GAR
        uses: docker/login-action@v2
        with:
          registry: '${{ env.REGION }}-docker.pkg.dev'
          username: _json_key
          password: ${{ secrets.GCP_CREDENTIALS }}

      - name: Build and Push Container
        run: |-
          docker build -t "${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/prefect:latest" -f Dockerfile.gcp .
          docker push "${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/prefect:latest"

#      - name: Build and Push Container
#        run: |-
#          docker build -t "${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/prefect:${{ github.sha }}" -f Dockerfile.gcp .
#          docker push "${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.AR_REPOSITORY }}/prefect:${{ github.sha }}"
#
#      - name: Create Blocks
#        id: gcp_blocks
#        run: |
#          cat <<EOF > gcp_blocks.py
#          from prefect_gcp.cloud_run import CloudRunJob
#          from prefect_gcp.credentials import GcpCredentials
#          from prefect.filesystems import GCS
#
#          sa = "${{ secrets.GCP_CREDENTIALS }}"
#
#          creds = GcpCredentials(service_account_info=sa)
#          gcs = GCS(service_account_info=sa, bucket_path="prefect-orion/flows")
#
#          id_ = "${{ secrets.AWS_ACCESS_KEY_ID }}"
#          key_ = "${{ secrets.AWS_SECRET_ACCESS_KEY }}"
#          path_ = "${{ github.event.inputs.gcs_path }}"
#          img_ = "${{ needs.ecr-repo.outputs.image }}"
#          block_ = "$BLOCK"
#          cluster_ = "${{ env.ECS_CLUSTER }}"
#          cpu_ = "${{ github.event.inputs.cpu }}"
#          memory_ = "${{ github.event.inputs.memory }}"
#          aws_acc_id = "$AWS_ACCOUNT_ID"
#          exec_role = f"arn:aws:iam::{aws_acc_id}:role/dataflowops_ecs_execution_role"
#          task_role = f"arn:aws:iam::{aws_acc_id}:role/dataflowops_ecs_execution_role"
#
#          aws_creds = AwsCredentials(aws_access_key_id=id_, aws_secret_access_key=key_)
#          aws_creds.save(block_, overwrite=True)
#
#          gcs = GCS(bucket_path=path_, aws_access_key_id=id_, aws_secret_access_key=key_)
#          gcs.save(block_, overwrite=True)
#
#          ecs = ECSTask(
#              aws_credentials=aws_creds,
#              image=img_,
#              cpu=cpu_,
#              memory=memory_,
#              stream_output=True,
#              configure_cloudwatch_logs=True,
#              cluster=cluster_,
#              execution_role_arn=exec_role,
#              task_role_arn=task_role,
#          )
#          ecs.save(block_, overwrite=True)
#          EOF
#          python aws_ecs_blocks.py
